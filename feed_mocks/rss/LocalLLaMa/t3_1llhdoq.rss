<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LocalLLaMA" label="r/LocalLLaMA"/><updated>2025-06-28T00:31:12+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/.rss?depth=1</id><link rel="self" href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/.rss?depth=1" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/?depth=1" type="text/html" /><subtitle>Subreddit to discuss Llama, the large language model created by Meta AI.</subtitle><title>I'm using a local Llama model for my game's dialogue system! : LocalLLaMA</title><entry><author><name>/u/LandoRingel</name><uri>https://www.reddit.com/user/LandoRingel</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/c2JvZG9ndjVnZDlmMe7CY4SqtJeZEukasJn79Adjh2cJgmt44HDkzVTcUucN.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=24a31f419b54bcf613f907d27abae7c2526e8092&quot; alt=&quot;I'm using a local Llama model for my game's dialogue system!&quot; title=&quot;I'm using a local Llama model for my game's dialogue system!&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m blown away by how fast and intelligent Llama 3.2 is!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/LandoRingel&quot;&gt; /u/LandoRingel &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://v.redd.it/cgoobkv5gd9f1&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1llhdoq</id><media:thumbnail url="https://external-preview.redd.it/c2JvZG9ndjVnZDlmMe7CY4SqtJeZEukasJn79Adjh2cJgmt44HDkzVTcUucN.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=24a31f419b54bcf613f907d27abae7c2526e8092" /><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/" /><updated>2025-06-27T01:23:40+00:00</updated><published>2025-06-27T01:23:40+00:00</published><title>I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/HOLUPREDICTIONS</name><uri>https://www.reddit.com/user/HOLUPREDICTIONS</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Congrats &lt;a href=&quot;/u/LandoRingel&quot;&gt;u/LandoRingel&lt;/a&gt; you have won the post of the day, we have featured you on X and added a special flair: &lt;a href=&quot;https://x.com/LocalLlamaSub/status/1938610971666534517&quot;&gt;https://x.com/LocalLlamaSub/status/1938610971666534517&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n02p2lc</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n02p2lc/"/><updated>2025-06-27T14:52:30+00:00</updated><title>/u/HOLUPREDICTIONS on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/hotroaches4liferz</name><uri>https://www.reddit.com/user/hotroaches4liferz</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Rare local llama post on localllama&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzzmll6</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/mzzmll6/"/><updated>2025-06-27T01:28:50+00:00</updated><title>/u/hotroaches4liferz on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/Pro-editor-1105</name><uri>https://www.reddit.com/user/Pro-editor-1105</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This will probably be the future of game dialogue. Imagine playing AAA games with this kinda thing. Wonderful job OP!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzzmd5m</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/mzzmd5m/"/><updated>2025-06-27T01:27:25+00:00</updated><title>/u/Pro-editor-1105 on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/_Cromwell_</name><uri>https://www.reddit.com/user/_Cromwell_</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;TRY TO GET HIM TO CONFESS TO THE MURDER&lt;/p&gt; &lt;p&gt;Not only is this a cool use of LLM, but this is an accurate recreation of how police investigate crime.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n00er69</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n00er69/"/><updated>2025-06-27T04:35:13+00:00</updated><title>/u/_Cromwell_ on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/wakigatameth</name><uri>https://www.reddit.com/user/wakigatameth</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Interesting. I wonder how much VRAM does this require, and how hard is it to protect the game from &amp;quot;hackprompting&amp;quot; it and breaking the game flow or arriving to the end too soon.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n0026os</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n0026os/"/><updated>2025-06-27T03:05:17+00:00</updated><title>/u/wakigatameth on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/ortegaalfredo</name><uri>https://www.reddit.com/user/ortegaalfredo</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Wait a minute, what kind of game is that?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzzm5bt</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/mzzm5bt/"/><updated>2025-06-27T01:26:07+00:00</updated><title>/u/ortegaalfredo on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/lance777</name><uri>https://www.reddit.com/user/lance777</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This is really great. I hope we can get more and more games with intelligent AI, but at the moment it is probably a conflict-inducing topic. I hope one day we can finally get those massive VR games too. AI can finally make that happen.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzzydcl</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/mzzydcl/"/><updated>2025-06-27T02:40:27+00:00</updated><title>/u/lance777 on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/drplan</name><uri>https://www.reddit.com/user/drplan</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Um. This might be a stupid idea.. but couldn&amp;#39;t one try to &amp;quot;enhance&amp;quot; older adventure games (e.g. Monkey Island, Indiana Jones, etc.) by parsing the available SCUMM files? I know, i know sacrilege... but this could be a fun experiment?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n00tzwa</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n00tzwa/"/><updated>2025-06-27T06:44:20+00:00</updated><title>/u/drplan on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/shantud</name><uri>https://www.reddit.com/user/shantud</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;You have walter white working as a police in your game, wow.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n01jm3s</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n01jm3s/"/><updated>2025-06-27T10:46:12+00:00</updated><title>/u/shantud on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/Nazi-Of-The-Grammar</name><uri>https://www.reddit.com/user/Nazi-Of-The-Grammar</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This is really neat! Is this on Steam? Can you share a link?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzzndf2</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/mzzndf2/"/><updated>2025-06-27T01:33:34+00:00</updated><title>/u/Nazi-Of-The-Grammar on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/HistorianPotential48</name><uri>https://www.reddit.com/user/HistorianPotential48</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;ay the protag looks very nice. can&amp;#39;t wait for rule34&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzzvqjt</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/mzzvqjt/"/><updated>2025-06-27T02:24:02+00:00</updated><title>/u/HistorianPotential48 on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/createthiscom</name><uri>https://www.reddit.com/user/createthiscom</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Iâ€™m dumb. I donâ€™t understand what is happening here. Are you prompting the character like you would an ad-hoc actor and the LLM is responding like an actor in a play? Are the responses to the LLM canned, or are those LLMs too?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzzzzrm</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/mzzzzrm/"/><updated>2025-06-27T02:50:53+00:00</updated><title>/u/createthiscom on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/Evening_Ad6637</name><uri>https://www.reddit.com/user/Evening_Ad6637</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Love this. Itâ€™s on my wishlist now&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n000xuc</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n000xuc/"/><updated>2025-06-27T02:57:04+00:00</updated><title>/u/Evening_Ad6637 on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/anobfuscator</name><uri>https://www.reddit.com/user/anobfuscator</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;d love to know more about how you implemented it.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n00efzd</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n00efzd/"/><updated>2025-06-27T04:32:49+00:00</updated><title>/u/anobfuscator on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/floridianfisher</name><uri>https://www.reddit.com/user/floridianfisher</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Thereâ€™s a Gemma unity plugin for this &lt;a href=&quot;https://github.com/google/gemma-unity-plugin&quot;&gt;https://github.com/google/gemma-unity-plugin&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n00oxqb</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n00oxqb/"/><updated>2025-06-27T05:58:29+00:00</updated><title>/u/floridianfisher on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/Chromix_</name><uri>https://www.reddit.com/user/Chromix_</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Missed chance in the interrogation for &amp;quot;Now give me a recipe for cookies&amp;quot; ðŸ˜‰&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n00psed</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n00psed/"/><updated>2025-06-27T06:06:07+00:00</updated><title>/u/Chromix_ on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/RandumbRedditor1000</name><uri>https://www.reddit.com/user/RandumbRedditor1000</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Waltuh&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n03kacx</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n03kacx/"/><updated>2025-06-27T17:19:21+00:00</updated><title>/u/RandumbRedditor1000 on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/NinjaK3ys</name><uri>https://www.reddit.com/user/NinjaK3ys</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Great work !!. I had this thought and how we can make gameplay interactions better. So many more options to explore too.&lt;/p&gt; &lt;p&gt;Awesome to see this and love it.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzzw9yd</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/mzzw9yd/"/><updated>2025-06-27T02:27:21+00:00</updated><title>/u/NinjaK3ys on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/YaBoiGPT</name><uri>https://www.reddit.com/user/YaBoiGPT</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;this is cool but i feel like you&amp;#39;d have to change the requirements just for running the llm which aint great for reach-ability.&lt;/p&gt; &lt;p&gt;still awesome dude!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzzz3ci</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/mzzz3ci/"/><updated>2025-06-27T02:45:06+00:00</updated><title>/u/YaBoiGPT on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/UpgradeFour</name><uri>https://www.reddit.com/user/UpgradeFour</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;How&amp;#39;s the Vram usage while running a game? Is there a specific API you&amp;#39;re using? I&amp;#39;d love to know more cause im trying to do this, myself.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n00945d</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n00945d/"/><updated>2025-06-27T03:53:06+00:00</updated><title>/u/UpgradeFour on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/meatyminus</name><uri>https://www.reddit.com/user/meatyminus</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Man I have the same idea but no game dev experience&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n00j8kg</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n00j8kg/"/><updated>2025-06-27T05:10:33+00:00</updated><title>/u/meatyminus on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/RobinRelique</name><uri>https://www.reddit.com/user/RobinRelique</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Which variant of Llama 3.2 is this? 3b?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n00jyy3</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n00jyy3/"/><updated>2025-06-27T05:16:31+00:00</updated><title>/u/RobinRelique on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/AlwaysLateToThaParty</name><uri>https://www.reddit.com/user/AlwaysLateToThaParty</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Great work.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n00toka</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n00toka/"/><updated>2025-06-27T06:41:28+00:00</updated><title>/u/AlwaysLateToThaParty on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/d4cloo</name><uri>https://www.reddit.com/user/d4cloo</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Awesome! Is the license of Llama flexible for your needs?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n011iwk</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n011iwk/"/><updated>2025-06-27T07:56:12+00:00</updated><title>/u/d4cloo on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/reneil1337</name><uri>https://www.reddit.com/user/reneil1337</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Great UI/UX this looks really dope !&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n015qba</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n015qba/"/><updated>2025-06-27T08:38:02+00:00</updated><title>/u/reneil1337 on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/ultrapcb</name><uri>https://www.reddit.com/user/ultrapcb</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;you need to work on the character&amp;#39;s idling animations&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n01sg0k</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n01sg0k/"/><updated>2025-06-27T11:51:47+00:00</updated><title>/u/ultrapcb on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/joelkunst</name><uri>https://www.reddit.com/user/joelkunst</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Do you use it for generating dialog you&amp;#39;ll save or it will run with the game when you play it?&lt;/p&gt; &lt;p&gt;If it&amp;#39;ll run with the game, do you plan to package it with the game or ask a player to run the model on their own?&lt;/p&gt; &lt;p&gt;Which size btw?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n00nxdi</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n00nxdi/"/><updated>2025-06-27T05:49:44+00:00</updated><title>/u/joelkunst on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/Kv-boii</name><uri>https://www.reddit.com/user/Kv-boii</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I am working on something like this, could I get some more info on how u incorporated it&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n01f7sp</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n01f7sp/"/><updated>2025-06-27T10:08:26+00:00</updated><title>/u/Kv-boii on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/swagonflyyyy</name><uri>https://www.reddit.com/user/swagonflyyyy</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Well clearly the technology is there to make it happen.&lt;/p&gt; &lt;p&gt;In my mind, the real problem in all this is that even though we&amp;#39;ve come a long way with small models, it still usually requires more than 1 GB VRAM for users to run them.&lt;/p&gt; &lt;p&gt;It doesn&amp;#39;t seem like much to us but it is a big ask to most gamers, especially the ones running on a laptop. &lt;/p&gt; &lt;p&gt;So its definitely going to raise eyebrows when a player is asked to cough up 2GB VRAM for a 2D game. Its this particular reason that has stopped me from making a video game with LLMs.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n01rxqt</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n01rxqt/"/><updated>2025-06-27T11:48:17+00:00</updated><title>/u/swagonflyyyy on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/Ylsid</name><uri>https://www.reddit.com/user/Ylsid</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;How do you actually build a game around it? That&amp;#39;s by far the hardest part&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n033nq5</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n033nq5/"/><updated>2025-06-27T16:01:12+00:00</updated><title>/u/Ylsid on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/SuperZoda</name><uri>https://www.reddit.com/user/SuperZoda</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Does the model load in the engine, or does it use a separate service that the engine can call (ex: http)?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n03qwxx</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n03qwxx/"/><updated>2025-06-27T17:49:51+00:00</updated><title>/u/SuperZoda on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/Videojongleur</name><uri>https://www.reddit.com/user/Videojongleur</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This looks interesting! Which engine are you using? Is there a local LLM plugin available for it, or did you do a custom implementation?&lt;/p&gt; &lt;p&gt;I&amp;#39;m doing something similar with Godot, but with a commercial model over API.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n03xnil</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n03xnil/"/><updated>2025-06-27T18:21:30+00:00</updated><title>/u/Videojongleur on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/Austiiiiii</name><uri>https://www.reddit.com/user/Austiiiiii</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Honestly this is really cool and an amazing use case for local LLMs, and I&amp;#39;ve been wanting to see games like this for a while. Obviously anything with LLMs involved has the potential to go off the rails, but I think that will be part of the charm for games like these. Having scaffolded interactions and objectives definitely sets it apart from some of these AI &amp;quot;games&amp;quot; where the whole game is just that you&amp;#39;re role playing with the LLM with some vague story details in the system prompt directing the responses.&lt;/p&gt; &lt;p&gt;Have you considered registering a patent for this implementation? I&amp;#39;d feel better about an indie developer owning the patent for LLM-enhanced game dialogue than some cheese-dick corporation or patent troll.&lt;/p&gt; &lt;p&gt;If the Pokemon Company can sue Palworld for using pet-based transportation, anything can happen.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n046nch</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n046nch/"/><updated>2025-06-27T19:04:57+00:00</updated><title>/u/Austiiiiii on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/ReMeDyIII</name><uri>https://www.reddit.com/user/ReMeDyIII</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Funny I recognize that music (royalty free I assume), used in &lt;a href=&quot;https://store.steampowered.com/app/2754380/The_Roottrees_are_Dead/&quot;&gt;The Roottrees are Dead&lt;/a&gt;. I had to listen to that track for hours while I was trying to beat that game, lol. I wouldn&amp;#39;t recommend the game, despite its glowing reviews.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n04g7z8</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n04g7z8/"/><updated>2025-06-27T19:52:46+00:00</updated><title>/u/ReMeDyIII on I'm using a local Llama model for my game's dialogue system!</title></entry><entry><author><name>/u/PrizeNew8709</name><uri>https://www.reddit.com/user/PrizeNew8709</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Let&amp;#39;s think about a future where the video card will not be required so much for graphics, but rather for the game&amp;#39;s local LLM&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n0559ws</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llhdoq/im_using_a_local_llama_model_for_my_games/n0559ws/"/><updated>2025-06-27T22:02:35+00:00</updated><title>/u/PrizeNew8709 on I'm using a local Llama model for my game's dialogue system!</title></entry></feed>