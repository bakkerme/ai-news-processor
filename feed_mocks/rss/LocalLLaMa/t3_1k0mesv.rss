<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LocalLLaMA" label="r/LocalLLaMA"/><updated>2025-04-21T06:26:16+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/.rss?depth=1</id><link rel="self" href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/.rss?depth=1" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/?depth=1" type="text/html" /><subtitle>Subreddit to discuss about Llama, the large language model created by Meta AI.</subtitle><title>IBM Granite 3.3 Models : LocalLLaMA</title><entry><author><name>/u/suitable_cowboy</name><uri>https://www.reddit.com/user/suitable_cowboy</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/Di-LJPiKH5-hlOr8JOzFQOIzNY3wtbEXkzZj38FaUy4.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=cea64ef12850fb58da12ba852867d09166207a09&quot; alt=&quot;IBM Granite 3.3 Models&quot; title=&quot;IBM Granite 3.3 Models&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.ibm.com/new/announcements/ibm-granite-3-3-speech-recognition-refined-reasoning-rag-loras&quot;&gt;Announcement Post&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://huggingface.co/ibm-granite/granite-speech-3.3-8b&quot;&gt;3.3 Speech Model&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/suitable_cowboy&quot;&gt; /u/suitable_cowboy &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://huggingface.co/collections/ibm-granite/granite-33-language-models-67f65d0cca24bcbd1d3a08e3&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1k0mesv</id><media:thumbnail url="https://external-preview.redd.it/Di-LJPiKH5-hlOr8JOzFQOIzNY3wtbEXkzZj38FaUy4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cea64ef12850fb58da12ba852867d09166207a09" /><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/" /><updated>2025-04-16T14:54:48+00:00</updated><published>2025-04-16T14:54:48+00:00</published><title>IBM Granite 3.3 Models</title></entry><entry><author><name>/u/ibm</name><uri>https://www.reddit.com/user/ibm</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Let us know if you have any questions about Granite 3.3!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnf64fc</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnf64fc/"/><updated>2025-04-16T15:11:09+00:00</updated><title>/u/ibm on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/ApprehensiveAd3629</name><uri>https://www.reddit.com/user/ApprehensiveAd3629</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Yeah I like granite models(gpu poor here) Lets test now&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnf6357</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnf6357/"/><updated>2025-04-16T15:10:58+00:00</updated><title>/u/ApprehensiveAd3629 on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/Bakoro</name><uri>https://www.reddit.com/user/Bakoro</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I know I shouldn&amp;#39;t, but I keep completely forgetting that IBM is a company that still does things sometimes.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnfehxc</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnfehxc/"/><updated>2025-04-16T15:52:24+00:00</updated><title>/u/Bakoro on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/ilintar</name><uri>https://www.reddit.com/user/ilintar</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;My silent favorite among the small models, nice to see another iteration.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnfk4xf</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnfk4xf/"/><updated>2025-04-16T16:20:26+00:00</updated><title>/u/ilintar on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/thescientificindian</name><uri>https://www.reddit.com/user/thescientificindian</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This is nice work. Thanks for sharing here.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnfauuf</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnfauuf/"/><updated>2025-04-16T15:34:31+00:00</updated><title>/u/thescientificindian on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/letsgeditmedia</name><uri>https://www.reddit.com/user/letsgeditmedia</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;What is the best use case for this model ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnfceza</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnfceza/"/><updated>2025-04-16T15:42:10+00:00</updated><title>/u/letsgeditmedia on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/arm2armreddit</name><uri>https://www.reddit.com/user/arm2armreddit</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;BTW, 3.2 was pretty neat and nice. Going to test 3.3. Thanks for open-weighting them.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnfwbe5</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnfwbe5/"/><updated>2025-04-16T17:19:22+00:00</updated><title>/u/arm2armreddit on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/FriskyFennecFox</name><uri>https://www.reddit.com/user/FriskyFennecFox</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Granite-3.3 scores lower than Granite-3.1 ? How comes?&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://preview.redd.it/kme7581bv7ve1.png?width=924&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c1cfb3ceadaac8d09b6f96e7d24a53e64e4847df&quot;&gt;https://preview.redd.it/kme7581bv7ve1.png?width=924&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c1cfb3ceadaac8d09b6f96e7d24a53e64e4847df&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnfbqqs</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnfbqqs/"/><updated>2025-04-16T15:38:54+00:00</updated><title>/u/FriskyFennecFox on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/crazyfreak316</name><uri>https://www.reddit.com/user/crazyfreak316</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Looks like everyone apart from &amp;quot;Open&amp;quot;AI is releasing open source models.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mngy380</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mngy380/"/><updated>2025-04-16T20:26:06+00:00</updated><title>/u/crazyfreak316 on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/wapxmas</name><uri>https://www.reddit.com/user/wapxmas</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&amp;quot;can be integrated into AI assistants across various domains&amp;quot;&lt;br/&gt; 8b?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnf4axj</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnf4axj/"/><updated>2025-04-16T15:02:07+00:00</updated><title>/u/wapxmas on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/noage</name><uri>https://www.reddit.com/user/noage</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;The two pass approach for the speech model seems interesting. The trade off seems to be keeping the 8b llm free from degradation by not making it truly multimodal in it&amp;#39;s entirety. But, does that overall have benefit compared to using a discrete speech model and another llm? How many parameters does the speech model component use and are there speed benefits compared to a one pass multimodal model?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnf8qck</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnf8qck/"/><updated>2025-04-16T15:24:05+00:00</updated><title>/u/noage on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/dubesor86</name><uri>https://www.reddit.com/user/dubesor86</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I tested it (f16), and it actually scored a bit worse than the Granite 3.0 Q8 I tested 6 months ago.&lt;/p&gt; &lt;p&gt;Not the absolute worst, but just utterly uninteresting and beaten by a plethora of other models in the same size segment in pretty much all tested fields.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnfzsl7</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnfzsl7/"/><updated>2025-04-16T17:35:46+00:00</updated><title>/u/dubesor86 on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/prince_pringle</name><uri>https://www.reddit.com/user/prince_pringle</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Dafuq?! Ok ibm, I see you interacting here and I didn‚Äôt expect that. I‚Äôm mainly interested in aider success % vs cost benchmarks these days because I‚Äôm a moron. Any of those out yet?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mng7fm9</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mng7fm9/"/><updated>2025-04-16T18:12:04+00:00</updated><title>/u/prince_pringle on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/bennmann</name><uri>https://www.reddit.com/user/bennmann</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;i would be very interested in a history lesson from the granite team concerning long past IBM Watson to present day LLMs from IBM perspective&lt;/p&gt; &lt;p&gt;Watson was ahead of it&amp;#39;s time. would love a blog post.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnh0snb</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnh0snb/"/><updated>2025-04-16T20:39:24+00:00</updated><title>/u/bennmann on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/relmny</name><uri>https://www.reddit.com/user/relmny</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Didn&amp;#39;t care much at first, but being that (it seems like) IBM decided to have someone participating here by answering questions and providing more information... I will give it a try.&lt;/p&gt; &lt;p&gt;Nice move IBM!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnjpt1d</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnjpt1d/"/><updated>2025-04-17T07:24:27+00:00</updated><title>/u/relmny on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/zacksiri</name><uri>https://www.reddit.com/user/zacksiri</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;These models are really really good I&amp;#39;m working with the 8b variant. They&amp;#39;re very straight and to the point with their outputs. Which works well in an agentic system with lots of structured output and tool calling.&lt;/p&gt; &lt;p&gt;Function / Tool calling works really well. I&amp;#39;ve compared them to Gemma 3 12b and Mistral Small 24b, Qwen 2.5 14b&lt;/p&gt; &lt;p&gt;The output from them are quite amazing in my benchmark. It definitely beats Qwen 2.5 14b and is comparable to Gemma 3 12b and Mistral Small 24b. This model definitely punches above it&amp;#39;s weight when it comes to agentic systems. At least for my use case.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnwj9f5</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnwj9f5/"/><updated>2025-04-19T09:53:48+00:00</updated><title>/u/zacksiri on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/Mr-Barack-Obama</name><uri>https://www.reddit.com/user/Mr-Barack-Obama</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;when guff&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnfbnlo</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnfbnlo/"/><updated>2025-04-16T15:38:28+00:00</updated><title>/u/Mr-Barack-Obama on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/mhawk12</name><uri>https://www.reddit.com/user/mhawk12</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Wow! Pleased to see IBM engaging with the community.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mngg7lh</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mngg7lh/"/><updated>2025-04-16T18:56:35+00:00</updated><title>/u/mhawk12 on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/Ayush1733433</name><uri>https://www.reddit.com/user/Ayush1733433</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Will there be INT8/QAT variants on Hugging Face? Smaller deployment footprints would be huge for local apps.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mngijbd</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mngijbd/"/><updated>2025-04-16T19:08:37+00:00</updated><title>/u/Ayush1733433 on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/Prestigious_Ebb_1767</name><uri>https://www.reddit.com/user/Prestigious_Ebb_1767</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This is cool.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mni1b4l</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mni1b4l/"/><updated>2025-04-16T23:59:05+00:00</updated><title>/u/Prestigious_Ebb_1767 on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/sunomonodekani</name><uri>https://www.reddit.com/user/sunomonodekani</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Thank you for your effort, from the bottom of my heart ‚ù§Ô∏è But it&amp;#39;s just another completely expendable model, just like the other versions of Granite. The feeling it gives is that we are using a Llama who learned to say that he was created by IBM.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnj4qhi</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnj4qhi/"/><updated>2025-04-17T04:12:30+00:00</updated><title>/u/sunomonodekani on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/silenceimpaired</name><uri>https://www.reddit.com/user/silenceimpaired</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I wonder how Granite Speech 3.3 8B will compare against whisper&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnfo4bh</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnfo4bh/"/><updated>2025-04-16T16:40:14+00:00</updated><title>/u/silenceimpaired on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/silenceimpaired</name><uri>https://www.reddit.com/user/silenceimpaired</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;IBM: fix this grammar ;)&lt;/p&gt; &lt;p&gt;Emotion detection: Future Granite Speech models will -be- support speech emotion recognition (SER) capabilities through training our acoustic encoder to be more sensitive to non-lexical audio events.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnfp8ww</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnfp8ww/"/><updated>2025-04-16T16:45:43+00:00</updated><title>/u/silenceimpaired on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/silenceimpaired</name><uri>https://www.reddit.com/user/silenceimpaired</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Excited to try Filling in the middle, but I wonder how easy it will be to do in some platforms.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnfqnfl</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnfqnfl/"/><updated>2025-04-16T16:52:28+00:00</updated><title>/u/silenceimpaired on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/AliNT77</name><uri>https://www.reddit.com/user/AliNT77</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;is there going to be QAT versions available like gemma3 ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnfrsic</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnfrsic/"/><updated>2025-04-16T16:57:53+00:00</updated><title>/u/AliNT77 on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/ForsookComparison</name><uri>https://www.reddit.com/user/ForsookComparison</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I freaking loved Granite 3.2&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnfx27x</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnfx27x/"/><updated>2025-04-16T17:22:52+00:00</updated><title>/u/ForsookComparison on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/ManufacturerHuman937</name><uri>https://www.reddit.com/user/ManufacturerHuman937</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;About how much VRAM to use this at full context when factoring in Q8?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mng1z5c</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mng1z5c/"/><updated>2025-04-16T17:45:59+00:00</updated><title>/u/ManufacturerHuman937 on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/alonenos</name><uri>https://www.reddit.com/user/alonenos</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is there Turkish language support?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mng7bph</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mng7bph/"/><updated>2025-04-16T18:11:31+00:00</updated><title>/u/alonenos on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/JacketHistorical2321</name><uri>https://www.reddit.com/user/JacketHistorical2321</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Are these somewhat optimized for power systems? Do you have any guides for running inference on power 8 if so?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mngciki</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mngciki/"/><updated>2025-04-16T18:37:43+00:00</updated><title>/u/JacketHistorical2321 on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/HarambeTenSei</name><uri>https://www.reddit.com/user/HarambeTenSei</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Multilingual when?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnhtmk4</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnhtmk4/"/><updated>2025-04-16T23:15:43+00:00</updated><title>/u/HarambeTenSei on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/Zc5Gwu</name><uri>https://www.reddit.com/user/Zc5Gwu</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I wonder how this compares to &lt;a href=&quot;https://huggingface.co/deepcogito/cogito-v1-preview-llama-8B&quot;&gt;Cogito v1 preview - 8B&lt;/a&gt;? If the metrics are anything to go off of, granite seems better at math but worse at everything else?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnilm3o</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnilm3o/"/><updated>2025-04-17T02:03:35+00:00</updated><title>/u/Zc5Gwu on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/mgr2019x</name><uri>https://www.reddit.com/user/mgr2019x</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;It is not bad for its size. Good instruction following. Sadly, it hallucinates. But that&amp;#39;s due to its size. I wonder how a decent sized version would perfom. ü§ì&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnnwdhy</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnnwdhy/"/><updated>2025-04-17T22:15:42+00:00</updated><title>/u/mgr2019x on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/InevitableFunny8870</name><uri>https://www.reddit.com/user/InevitableFunny8870</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;How to enable thinking capability for granite 3.3 on lm studio ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mns2d1u</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mns2d1u/"/><updated>2025-04-18T16:05:55+00:00</updated><title>/u/InevitableFunny8870 on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/Jotschi</name><uri>https://www.reddit.com/user/Jotschi</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Will the Granite 3.3 Base Model be used to create a MoE reasoning model?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnxtefo</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnxtefo/"/><updated>2025-04-19T15:21:06+00:00</updated><title>/u/Jotschi on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/sunomonodekani</name><uri>https://www.reddit.com/user/sunomonodekani</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;It&amp;#39;s a huge shame that the speech model only supports English.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnhhm51</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnhhm51/"/><updated>2025-04-16T22:07:58+00:00</updated><title>/u/sunomonodekani on IBM Granite 3.3 Models</title></entry><entry><author><name>/u/lqstuart</name><uri>https://www.reddit.com/user/lqstuart</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;lol IBM&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnlaem3</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0mesv/ibm_granite_33_models/mnlaem3/"/><updated>2025-04-17T14:32:24+00:00</updated><title>/u/lqstuart on IBM Granite 3.3 Models</title></entry></feed>