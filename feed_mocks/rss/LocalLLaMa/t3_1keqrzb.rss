<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LocalLLaMA" label="r/LocalLLaMA"/><updated>2025-05-05T05:32:21+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LocalLLaMA/comments/1keqrzb/super_simple_rag/.rss?depth=1</id><link rel="self" href="https://www.reddit.com/r/LocalLLaMA/comments/1keqrzb/super_simple_rag/.rss?depth=1" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LocalLLaMA/comments/1keqrzb/super_simple_rag/?depth=1" type="text/html" /><subtitle>Subreddit to discuss about Llama, the large language model created by Meta AI.</subtitle><title>Super simple RAG? : LocalLLaMA</title><entry><author><name>/u/9acca9</name><uri>https://www.reddit.com/user/9acca9</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I use LM-Studio, and I wanted to know if it&amp;#39;s useful to use an install-and-use RAG to ask questions about a set of books (text). Or is it the same as adding the book(s) to the LM-Studio chat (which, from what I noticed, also creates a RAG when you query (I saw it says something about &amp;quot;retrieval&amp;quot; and sending parts of the book)).&lt;/p&gt; &lt;p&gt;In that case, it might be useful. Which one do you recommend? (Or should I stick with what LM-Studio does?)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/9acca9&quot;&gt; /u/9acca9 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LocalLLaMA/comments/1keqrzb/super_simple_rag/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LocalLLaMA/comments/1keqrzb/super_simple_rag/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1keqrzb</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1keqrzb/super_simple_rag/" /><updated>2025-05-04T18:29:47+00:00</updated><published>2025-05-04T18:29:47+00:00</published><title>Super simple RAG?</title></entry><entry><author><name>/u/RHM0910</name><uri>https://www.reddit.com/user/RHM0910</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;AnythingLLM is better for This&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mql3hr9</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1keqrzb/super_simple_rag/mql3hr9/"/><updated>2025-05-04T19:26:07+00:00</updated><title>/u/RHM0910 on Super simple RAG?</title></entry><entry><author><name>/u/Pretend_Tour_9611</name><uri>https://www.reddit.com/user/Pretend_Tour_9611</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Also, you could use Msty, it has a friendly RAG feature. You can use your models from LM Studio (selecting the folder, chat and embedding model) and add your base knowledge (selecting a folder of PDF, Obsidian vault,etc), supports several doc types. It&amp;#39;s really simple way for simple RAG&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mqluxux</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1keqrzb/super_simple_rag/mqluxux/"/><updated>2025-05-04T21:50:38+00:00</updated><title>/u/Pretend_Tour_9611 on Super simple RAG?</title></entry><entry><author><name>/u/Sartorianby</name><uri>https://www.reddit.com/user/Sartorianby</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;LMS automatically pulls documents you&amp;#39;ve sent. In full if you have a large enough context length, as RAG if it&amp;#39;s too long to fit.&lt;/p&gt; &lt;p&gt;If it&amp;#39;s a book then maybe separating into chapters could make it even easier to process, but you&amp;#39;ll have to test it.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mql0pn0</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1keqrzb/super_simple_rag/mql0pn0/"/><updated>2025-05-04T19:11:20+00:00</updated><title>/u/Sartorianby on Super simple RAG?</title></entry></feed>