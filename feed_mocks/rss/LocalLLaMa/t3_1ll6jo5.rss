<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LocalLLaMA" label="r/LocalLLaMA"/><updated>2025-06-28T00:31:33+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/.rss?depth=1</id><link rel="self" href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/.rss?depth=1" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/?depth=1" type="text/html" /><subtitle>Subreddit to discuss Llama, the large language model created by Meta AI.</subtitle><title>DeepSeek R2 delayed : LocalLLaMA</title><entry><author><name>/u/FeathersOfTheArrow</name><uri>https://www.reddit.com/user/FeathersOfTheArrow</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/718m48of6b9f1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=9b5423692617bfdf316daec6232ca857bc69416c&quot; alt=&quot;DeepSeek R2 delayed&quot; title=&quot;DeepSeek R2 delayed&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;blockquote&gt; &lt;p&gt;Over the past several months, DeepSeek&amp;#39;s engineers have been working to refine R2 until Liang gives the green light for release, according to The Information. However, a fast adoption of R2 could be difficult due to a shortage of Nvidia server chips in China as a result of U.S. export regulations, the report said, citing employees of top Chinese cloud firms that offer DeepSeek&amp;#39;s models to enterprise customers.&lt;/p&gt; &lt;p&gt;A potential surge in demand for R2 would overwhelm Chinese cloud providers, who need advanced Nvidia chips to run AI models, the report said.&lt;/p&gt; &lt;p&gt;DeepSeek did not immediately respond to a Reuters request for comment.&lt;/p&gt; &lt;p&gt;DeepSeek has been in touch with some Chinese cloud companies, providing them with technical specifications to guide their plans for hosting and distributing the model from their servers, the report said.&lt;/p&gt; &lt;p&gt;Among its cloud customers currently using R1, the majority are running the model with Nvidia&amp;#39;s H20 chips, The Information said.&lt;/p&gt; &lt;p&gt;Fresh export curbs imposed by the Trump administration in April have prevented Nvidia from selling in the Chinese market its H20 chips - the only AI processors it could legally export to the country at the time.&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;Sources : &lt;a href=&quot;https://www.theinformation.com/articles/deepseeks-progress-stalled-u-s-export-controls&quot;&gt;[1]&lt;/a&gt; &lt;a href=&quot;https://x.com/kimmonismus/status/1938221881175183740&quot;&gt;[2]&lt;/a&gt; &lt;a href=&quot;https://www.reuters.com/world/china/deepseek-r2-launch-stalled-ceo-balks-progress-information-reports-2025-06-26/&quot;&gt;[3]&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/FeathersOfTheArrow&quot;&gt; /u/FeathersOfTheArrow &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/718m48of6b9f1.jpeg&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1ll6jo5</id><media:thumbnail url="https://preview.redd.it/718m48of6b9f1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9b5423692617bfdf316daec6232ca857bc69416c" /><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/" /><updated>2025-06-26T17:43:13+00:00</updated><published>2025-06-26T17:43:13+00:00</published><title>DeepSeek R2 delayed</title></entry><entry><author><name>/u/lordpuddingcup</name><uri>https://www.reddit.com/user/lordpuddingcup</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Deep Seek is the epitome of &amp;quot;let them cook&amp;quot; like, R1-0528 as such a amazing release, i have faith the delay is more than worth it.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzx8wn9</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzx8wn9/"/><updated>2025-06-26T17:57:21+00:00</updated><title>/u/lordpuddingcup on DeepSeek R2 delayed</title></entry><entry><author><name>/u/ForsookComparison</name><uri>https://www.reddit.com/user/ForsookComparison</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This is like when you&amp;#39;re still enjoying the best entre you&amp;#39;ve ever tasted and the waiter stops by to apologize that desert will be a few extra minutes.&lt;/p&gt; &lt;p&gt;R1-0528 will do for quite a while. Take your time, chef.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzx7vd6</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzx7vd6/"/><updated>2025-06-26T17:52:40+00:00</updated><title>/u/ForsookComparison on DeepSeek R2 delayed</title></entry><entry><author><name>/u/nullmove</name><uri>https://www.reddit.com/user/nullmove</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Reuters literally made up &amp;quot;R2&amp;quot; back in February citing &amp;quot;three people familiar to the company&amp;quot;. So obviously the next step is to claim R2 is delayed now that we got R1-0528 instead:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://www.reuters.com/technology/artificial-intelligence/deepseek-rushes-launch-new-ai-model-china-goes-all-2025-02-25/&quot;&gt;https://www.reuters.com/technology/artificial-intelligence/deepseek-rushes-launch-new-ai-model-china-goes-all-2025-02-25/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;They don&amp;#39;t know any more than you or I do, export control being an issue is something anyone can speculate. One has to be a blithering idiot to believe them again (which means we will get this spammed here all the time now).&lt;/p&gt; &lt;p&gt;We will have R2 once we have the new base model V4, the fact these articles don&amp;#39;t even bring up V4 speaks volume of their quality.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzxfjpm</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzxfjpm/"/><updated>2025-06-26T18:28:14+00:00</updated><title>/u/nullmove on DeepSeek R2 delayed</title></entry><entry><author><name>/u/ResidentPositive4122</name><uri>https://www.reddit.com/user/ResidentPositive4122</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Would R2 even work without dsv4? They RLd v3 and got R1, then the updated R1. There&amp;#39;s a chance they&amp;#39;ve reached the limits of v3. (some recent papers note that GRPO mainly surfaces what&amp;#39;s already in the base model, with limited if any new original stuff).&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzx8j82</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzx8j82/"/><updated>2025-06-26T17:55:41+00:00</updated><title>/u/ResidentPositive4122 on DeepSeek R2 delayed</title></entry><entry><author><name>/u/the_bollo</name><uri>https://www.reddit.com/user/the_bollo</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;More companies need to get serious about this. Don&amp;#39;t ship stuff because you&amp;#39;ve hit an arbitrary date - ship it when it&amp;#39;s &lt;em&gt;ready&lt;/em&gt;.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzxlwyy</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzxlwyy/"/><updated>2025-06-26T18:58:18+00:00</updated><title>/u/the_bollo on DeepSeek R2 delayed</title></entry><entry><author><name>/u/Sudden-Lingonberry-8</name><uri>https://www.reddit.com/user/Sudden-Lingonberry-8</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;they need to cook, please not a llama4 moment, nobody wants that&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzxp3bo</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzxp3bo/"/><updated>2025-06-26T19:13:37+00:00</updated><title>/u/Sudden-Lingonberry-8 on DeepSeek R2 delayed</title></entry><entry><author><name>/u/Ulterior-Motive_</name><uri>https://www.reddit.com/user/Ulterior-Motive_</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Let them cook&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzx7ze7</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzx7ze7/"/><updated>2025-06-26T17:53:10+00:00</updated><title>/u/Ulterior-Motive_ on DeepSeek R2 delayed</title></entry><entry><author><name>/u/JorG941</name><uri>https://www.reddit.com/user/JorG941</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;What about V4?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzxotgk</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzxotgk/"/><updated>2025-06-26T19:12:17+00:00</updated><title>/u/JorG941 on DeepSeek R2 delayed</title></entry><entry><author><name>/u/fiftyJerksInOneHuman</name><uri>https://www.reddit.com/user/fiftyJerksInOneHuman</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Good. Let it bake.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzx8gar</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzx8gar/"/><updated>2025-06-26T17:55:19+00:00</updated><title>/u/fiftyJerksInOneHuman on DeepSeek R2 delayed</title></entry><entry><author><name>/u/Pro-editor-1105</name><uri>https://www.reddit.com/user/Pro-editor-1105</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;He delayed the stock market crash lol&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzxnnm0</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzxnnm0/"/><updated>2025-06-26T19:06:36+00:00</updated><title>/u/Pro-editor-1105 on DeepSeek R2 delayed</title></entry><entry><author><name>/u/adumdumonreddit</name><uri>https://www.reddit.com/user/adumdumonreddit</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This is the reason why I never use the free deepseek endpoints. They deserve the money, they care about their product and deliver&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzxap4f</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzxap4f/"/><updated>2025-06-26T18:05:36+00:00</updated><title>/u/adumdumonreddit on DeepSeek R2 delayed</title></entry><entry><author><name>/u/Overflow_al</name><uri>https://www.reddit.com/user/Overflow_al</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Lol. R2 my ass. There ia no R2 unless V4 is released. Reuters made up shits said R2 will be released in May. And when it did not happen, they are like ohhh CEO delay, Chip shortage.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzz6rry</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzz6rry/"/><updated>2025-06-26T23:54:20+00:00</updated><title>/u/Overflow_al on DeepSeek R2 delayed</title></entry><entry><author><name>/u/Ancalagon_TheWhite</name><uri>https://www.reddit.com/user/Ancalagon_TheWhite</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;For context, It&amp;#39;s been less than a month since their last reasoning model R1 0528 came out.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzybuiy</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzybuiy/"/><updated>2025-06-26T21:06:55+00:00</updated><title>/u/Ancalagon_TheWhite on DeepSeek R2 delayed</title></entry><entry><author><name>/u/CaptainScrublord_</name><uri>https://www.reddit.com/user/CaptainScrublord_</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Let them cook, the new V3 and R1 are the proof of it.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzyflkp</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzyflkp/"/><updated>2025-06-26T21:25:46+00:00</updated><title>/u/CaptainScrublord_ on DeepSeek R2 delayed</title></entry><entry><author><name>/u/Rahaerys_Gaelanyon</name><uri>https://www.reddit.com/user/Rahaerys_Gaelanyon</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Achieving AGI with the power of long-termism 🫡&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n005c3t</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/n005c3t/"/><updated>2025-06-27T03:26:34+00:00</updated><title>/u/Rahaerys_Gaelanyon on DeepSeek R2 delayed</title></entry><entry><author><name>/u/Parking-Tomorrow-929</name><uri>https://www.reddit.com/user/Parking-Tomorrow-929</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Please, I’d much rather them take extra time and release a quality model&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n02z1w4</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/n02z1w4/"/><updated>2025-06-27T15:39:53+00:00</updated><title>/u/Parking-Tomorrow-929 on DeepSeek R2 delayed</title></entry><entry><author><name>/u/kholejones8888</name><uri>https://www.reddit.com/user/kholejones8888</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;ARM and unified memory supremacy bruh&lt;/p&gt; &lt;p&gt;They gonna do it they gonna dethrone nvidia fuck yeah&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzxqr1e</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzxqr1e/"/><updated>2025-06-26T19:21:42+00:00</updated><title>/u/kholejones8888 on DeepSeek R2 delayed</title></entry><entry><author><name>/u/Bakoro</name><uri>https://www.reddit.com/user/Bakoro</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I approve of this. In today&amp;#39;s ecosystem, there&amp;#39;s almost no point in putting out a model that is day-one second best in your class, your model have to be the best at &lt;em&gt;something&lt;/em&gt;, or else you&amp;#39;re just saying &amp;quot;we also exist&amp;quot;. &lt;/p&gt; &lt;p&gt;With Meta fumbling the last Llama release, nobody wants to be the next one to fumble.&lt;/p&gt; &lt;p&gt;Given the RL papers that have come out recently, it might make sense to implement those and just go straight to the next level.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzxr4q3</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzxr4q3/"/><updated>2025-06-26T19:23:34+00:00</updated><title>/u/Bakoro on DeepSeek R2 delayed</title></entry><entry><author><name>/u/Decaf_GT</name><uri>https://www.reddit.com/user/Decaf_GT</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Alternative take; now that Gemini, Claude, and OpenAI are all summarizing/hiding their full &amp;quot;thinking&amp;quot; process, DeepSeek can&amp;#39;t train on those reasoning outputs the same way they were (likely) doing before. &lt;/p&gt; &lt;p&gt;Deepseeks&amp;#39; methodology is great, the fact they released papers on it is fantastic. &lt;/p&gt; &lt;p&gt;But I never once bought the premise that they somehow magically created an o1-level reasoning model for &amp;quot;just a couple of million&amp;quot;, especially not when they conveniently don&amp;#39;t reveal where their training data comes from.&lt;/p&gt; &lt;p&gt;It&amp;#39;s really not that much of a mystery why all the frontier labs aren&amp;#39;t showing the exact step by step thinking process anymore and now are showing summarizations.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzxhelf</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzxhelf/"/><updated>2025-06-26T18:37:06+00:00</updated><title>/u/Decaf_GT on DeepSeek R2 delayed</title></entry><entry><author><name>/u/pier4r</name><uri>https://www.reddit.com/user/pier4r</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I don&amp;#39;t get it.&lt;/p&gt; &lt;p&gt;AFAIK there is a GPU shortage in China (as long as Chinese manufactured cannot reach a level similar to older nvidia gen). The OP text confirms that.&lt;/p&gt; &lt;p&gt;So I thought that every possible GPU would be used. Yet few months ago one would read: &lt;a href=&quot;https://www.tomshardware.com/tech-industry/artificial-intelligence/chinese-data-centers-refurbing-and-selling-rtx-4090s-due-to-overcapacity-48gb-models-sell-for-up-to-usd5-500&quot;&gt;Chinese data centers refurbing and selling Nvidia RTX 4090D GPUs due to overcapacity&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;What gives?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzxzngo</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzxzngo/"/><updated>2025-06-26T20:06:29+00:00</updated><title>/u/pier4r on DeepSeek R2 delayed</title></entry><entry><author><name>/u/no_witty_username</name><uri>https://www.reddit.com/user/no_witty_username</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Fair enough, it seems that the rumors of a &amp;quot;wall&amp;quot; are certainly showing to be true. Folks will just have to get more creative and mess around with other ways of putting generative AI systems together, no shortage of directions like diffusion (i think this is a good next area to look through), jeppa, and many other areas.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzy0m8b</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzy0m8b/"/><updated>2025-06-26T20:11:22+00:00</updated><title>/u/no_witty_username on DeepSeek R2 delayed</title></entry><entry><author><name>/u/ReMeDyIII</name><uri>https://www.reddit.com/user/ReMeDyIII</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;blockquote&gt; &lt;p&gt;A potential surge in demand for R2 would overwhelm Chinese cloud providers, who need advanced Nvidia chips to run AI models, the report said.&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;Might explain why direct DeepSeek&amp;#39;s API is always slow for me, yet it&amp;#39;s faster when I run NanoGPT as a middle-man into DeepSeek. Maybe DeepSeek has to prioritize API load to certain users over others.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzy5vec</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzy5vec/"/><updated>2025-06-26T20:37:30+00:00</updated><title>/u/ReMeDyIII on DeepSeek R2 delayed</title></entry><entry><author><name>/u/MrMrsPotts</name><uri>https://www.reddit.com/user/MrMrsPotts</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I don&amp;#39;t understand why they don&amp;#39;t smuggle GPUs from their neighbours as the Russians do with all their sanctioned goods.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzybitt</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzybitt/"/><updated>2025-06-26T21:05:15+00:00</updated><title>/u/MrMrsPotts on DeepSeek R2 delayed</title></entry><entry><author><name>/u/choose_a_guest</name><uri>https://www.reddit.com/user/choose_a_guest</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;How can it be delayed if they didn&amp;#39;t suggest any estimated time of arrival or release date?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzyk4af</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzyk4af/"/><updated>2025-06-26T21:49:01+00:00</updated><title>/u/choose_a_guest on DeepSeek R2 delayed</title></entry><entry><author><name>/u/Ok-Cucumber-7217</name><uri>https://www.reddit.com/user/Ok-Cucumber-7217</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Better that Zuck&amp;#39;s approach, for sure&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzyv9q0</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzyv9q0/"/><updated>2025-06-26T22:49:45+00:00</updated><title>/u/Ok-Cucumber-7217 on DeepSeek R2 delayed</title></entry><entry><author><name>/u/Few-Yam9901</name><uri>https://www.reddit.com/user/Few-Yam9901</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is there a V3 update or reconvertion of its gguf version that works with llama.cpp. current ggufs not up to date with recent llama.cpp improvements&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzz9zxx</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzz9zxx/"/><updated>2025-06-27T00:13:25+00:00</updated><title>/u/Few-Yam9901 on DeepSeek R2 delayed</title></entry><entry><author><name>/u/Cinderella-Yang</name><uri>https://www.reddit.com/user/Cinderella-Yang</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;this article is spewing bs. i had a dinner with Liang the other day, he told me R2 is going so smoothly that he thinks they already achieved AGI. but they are too afraid to release it because they dont want to be the destroyer of the world.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n00f1xy</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/n00f1xy/"/><updated>2025-06-27T04:37:33+00:00</updated><title>/u/Cinderella-Yang on DeepSeek R2 delayed</title></entry><entry><author><name>/u/bene_42069</name><uri>https://www.reddit.com/user/bene_42069</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Aren&amp;#39;t they starting to use more of those Huawei Ascends?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n00js8o</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/n00js8o/"/><updated>2025-06-27T05:15:00+00:00</updated><title>/u/bene_42069 on DeepSeek R2 delayed</title></entry><entry><author><name>/u/ganoliya</name><uri>https://www.reddit.com/user/ganoliya</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I don’t understand the thing with Nvidia chips. Why can’t they make their own chips? Or why some company in China cannot make similar/ better chips? They have been doing it with almost everything else right? Why so much dependency on nvidia chips?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n0294me</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/n0294me/"/><updated>2025-06-27T13:32:26+00:00</updated><title>/u/ganoliya on DeepSeek R2 delayed</title></entry><entry><author><name>/u/Ok-Recognition-3177</name><uri>https://www.reddit.com/user/Ok-Recognition-3177</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;LET THEM COOK&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzxduv1</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzxduv1/"/><updated>2025-06-26T18:20:22+00:00</updated><title>/u/Ok-Recognition-3177 on DeepSeek R2 delayed</title></entry><entry><author><name>/u/seeKAYx</name><uri>https://www.reddit.com/user/seeKAYx</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hopefully they will also get on the CLI bandwagon and come up with their own thing with the R2 model.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzxge5m</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzxge5m/"/><updated>2025-06-26T18:32:15+00:00</updated><title>/u/seeKAYx on DeepSeek R2 delayed</title></entry><entry><author><name>/u/DarkVoid42</name><uri>https://www.reddit.com/user/DarkVoid42</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;good. needs to blow the socks off everything else.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzxiui9</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzxiui9/"/><updated>2025-06-26T18:43:55+00:00</updated><title>/u/DarkVoid42 on DeepSeek R2 delayed</title></entry><entry><author><name>/u/InterstellarReddit</name><uri>https://www.reddit.com/user/InterstellarReddit</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This is what I love about Asian culture. &lt;/p&gt; &lt;p&gt;They&amp;#39;re more about quality than BSing investors. &lt;/p&gt; &lt;p&gt;They rather sit back and produce something of value. They dont try to crank out something minimal and claim this large amount of value behind it&lt;/p&gt; &lt;p&gt;Edit - apparently you all don&amp;#39;t understand what I was trying to say. &lt;/p&gt; &lt;p&gt;American companies will make a .01 revision update to a language model and claim a $200 billion evaluation on that update.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzxhpod</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzxhpod/"/><updated>2025-06-26T18:38:33+00:00</updated><title>/u/InterstellarReddit on DeepSeek R2 delayed</title></entry><entry><author><name>/u/ZiggityZaggityZoopoo</name><uri>https://www.reddit.com/user/ZiggityZaggityZoopoo</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Funnily? Almost every AI lab had this phase. Grok 3 had a failed training run. Claude 3.6 was rumored to be a brand new training run that didn’t match expectations. But it’s funny that DeepSeek only reached this moment now, they seemed to avoid the pitfalls that the others faced…&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzxswzz</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzxswzz/"/><updated>2025-06-26T19:32:22+00:00</updated><title>/u/ZiggityZaggityZoopoo on DeepSeek R2 delayed</title></entry><entry><author><name>/u/Odd-Brother1123</name><uri>https://www.reddit.com/user/Odd-Brother1123</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Really? I found &lt;a href=&quot;https://poe.com/DeepSeek-R2-OR&quot;&gt;R2 on Poe by OpenRouter.&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n001jpk</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/n001jpk/"/><updated>2025-06-27T03:01:00+00:00</updated><title>/u/Odd-Brother1123 on DeepSeek R2 delayed</title></entry><entry><author><name>/u/yetanotherbeardedone</name><uri>https://www.reddit.com/user/yetanotherbeardedone</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I believe, they are cooking a fully blown, brand new platform with Agents, MCPs, Artifacts, Vision, Image Generation and may be something new which we haven&amp;#39;t seen yet.&lt;/p&gt; &lt;p&gt;And considering the Agentic-terminal race we have been witnessing for quite a while, we could also get a Deepseek CLI-coder.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n01cfak</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/n01cfak/"/><updated>2025-06-27T09:43:00+00:00</updated><title>/u/yetanotherbeardedone on DeepSeek R2 delayed</title></entry><entry><author><name>/u/Altruistic_Plate1090</name><uri>https://www.reddit.com/user/Altruistic_Plate1090</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hace falta un V4 multimodal, no me importa que no sea mucho mejor en inteligencia que v3, solo les falta la multimodalidad para ser una alternativa al resto&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mzxxu8z</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1ll6jo5/deepseek_r2_delayed/mzxxu8z/"/><updated>2025-06-26T19:57:19+00:00</updated><title>/u/Altruistic_Plate1090 on DeepSeek R2 delayed</title></entry></feed>