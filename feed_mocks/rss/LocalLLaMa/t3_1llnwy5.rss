<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LocalLLaMA" label="r/LocalLLaMA"/><updated>2025-06-28T00:31:22+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LocalLLaMA/comments/1llnwy5/ai_performance_of_smartphone_socs/.rss?depth=1</id><link rel="self" href="https://www.reddit.com/r/LocalLLaMA/comments/1llnwy5/ai_performance_of_smartphone_socs/.rss?depth=1" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LocalLLaMA/comments/1llnwy5/ai_performance_of_smartphone_socs/?depth=1" type="text/html" /><subtitle>Subreddit to discuss Llama, the large language model created by Meta AI.</subtitle><title>AI performance of smartphone SoCs : LocalLLaMA</title><entry><author><name>/u/Balance-</name><uri>https://www.reddit.com/user/Balance-</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LocalLLaMA/comments/1llnwy5/ai_performance_of_smartphone_socs/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/H_9g87w3EitABPy3ZAOo2ZH9LlcpQ5L4KMiJgV1zrjo.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=baf972823fcd97a8af0b34ddd0ede97ce0d9de05&quot; alt=&quot;AI performance of smartphone SoCs&quot; title=&quot;AI performance of smartphone SoCs&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://ai-benchmark.com/ranking_processors.html&quot;&gt;https://ai-benchmark.com/ranking_processors.html&lt;/a&gt;&lt;/p&gt; &lt;p&gt;A few things notable to me: - The difference between tiers is &lt;em&gt;huge&lt;/em&gt;. A 2022 Snapdragon 8 Gen 2 beats the 8s Gen 4. There are huge gaps between the Dimensity 9000, 8000 and 7000 series. - You can better get a high-end SoC that’s a few years old than the latest mid-range one.&lt;/p&gt; &lt;h2&gt;- In this benchmark, it’s mainly a Qualcomm and Mediatek competition. It seems optimized software libraries are immensely important in using hardware effectively.&lt;/h2&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Balance-&quot;&gt; /u/Balance- &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/gallery/1llnwy5&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LocalLLaMA/comments/1llnwy5/ai_performance_of_smartphone_socs/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1llnwy5</id><media:thumbnail url="https://external-preview.redd.it/H_9g87w3EitABPy3ZAOo2ZH9LlcpQ5L4KMiJgV1zrjo.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=baf972823fcd97a8af0b34ddd0ede97ce0d9de05" /><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llnwy5/ai_performance_of_smartphone_socs/" /><updated>2025-06-27T07:34:42+00:00</updated><published>2025-06-27T07:34:42+00:00</published><title>AI performance of smartphone SoCs</title></entry><entry><author><name>/u/koumoua01</name><uri>https://www.reddit.com/user/koumoua01</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I wonder if 24GB ram, 1TB storage, 8gen3 phones could be useful? Demo devices with 99% new seem cost less than $300&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n011b1l</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llnwy5/ai_performance_of_smartphone_socs/n011b1l/"/><updated>2025-06-27T07:54:03+00:00</updated><title>/u/koumoua01 on AI performance of smartphone SoCs</title></entry><entry><author><name>/u/FullstackSensei</name><uri>https://www.reddit.com/user/FullstackSensei</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;It&amp;#39;s comparing NPU only. How would things stack if GPUs were involved?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n01899h</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llnwy5/ai_performance_of_smartphone_socs/n01899h/"/><updated>2025-06-27T09:02:44+00:00</updated><title>/u/FullstackSensei on AI performance of smartphone SoCs</title></entry><entry><author><name>/u/MMAgeezer</name><uri>https://www.reddit.com/user/MMAgeezer</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Worth noting that many of the devices tested here are using a now-depreciated Android API which notoriously doesn&amp;#39;t have great performance: &lt;a href=&quot;https://developer.android.com/ndk/guides/neuralnetworks/&quot;&gt;https://developer.android.com/ndk/guides/neuralnetworks/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n01bpuj</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llnwy5/ai_performance_of_smartphone_socs/n01bpuj/"/><updated>2025-06-27T09:36:19+00:00</updated><title>/u/MMAgeezer on AI performance of smartphone SoCs</title></entry><entry><author><name>/u/Klutzy-Snow8016</name><uri>https://www.reddit.com/user/Klutzy-Snow8016</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;The Google Tensor chips are embarrassing. They literally named them after AI acceleration, and look how slow they are.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n01bovn</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llnwy5/ai_performance_of_smartphone_socs/n01bovn/"/><updated>2025-06-27T09:36:05+00:00</updated><title>/u/Klutzy-Snow8016 on AI performance of smartphone SoCs</title></entry><entry><author><name>/u/sammcj</name><uri>https://www.reddit.com/user/sammcj</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I really wish iPhones had more RAM&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n025vk6</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llnwy5/ai_performance_of_smartphone_socs/n025vk6/"/><updated>2025-06-27T13:14:30+00:00</updated><title>/u/sammcj on AI performance of smartphone SoCs</title></entry><entry><author><name>/u/1overNseekness</name><uri>https://www.reddit.com/user/1overNseekness</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;any comparison to alternatives on desktop cpu ? to see advancements / track state of mobile ai perfs&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n015410</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llnwy5/ai_performance_of_smartphone_socs/n015410/"/><updated>2025-06-27T08:31:46+00:00</updated><title>/u/1overNseekness on AI performance of smartphone SoCs</title></entry><entry><author><name>/u/No_Conversation9561</name><uri>https://www.reddit.com/user/No_Conversation9561</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;where is exynos here?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n010hz1</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llnwy5/ai_performance_of_smartphone_socs/n010hz1/"/><updated>2025-06-27T07:46:04+00:00</updated><title>/u/No_Conversation9561 on AI performance of smartphone SoCs</title></entry><entry><author><name>/u/phhusson</name><uri>https://www.reddit.com/user/phhusson</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This doens&amp;#39;t apply to LLM though. First because I think there is pretty much no LLM on NPU use-case on Android. (Maybe Google&amp;#39;s Edge Gallery does?), and then because only prompt processing&amp;#39;s speed is ;o,oted by computation. Token Generation will be just as fast on CPU than on NPU on most smartphones. Maybe when we&amp;#39;ll see huge agents on Android it&amp;#39;ll get useful, but we&amp;#39;re still not there.&lt;/p&gt; &lt;p&gt;&amp;gt;You can better get a high-end SoC that’s a few years old than the latest mid-range one.&lt;/p&gt; &lt;p&gt;FWIW I&amp;#39;ve had smartphones since like 2006, and this statement has been true globally (not just NPU) since like 2010.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n01pca1</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llnwy5/ai_performance_of_smartphone_socs/n01pca1/"/><updated>2025-06-27T11:29:56+00:00</updated><title>/u/phhusson on AI performance of smartphone SoCs</title></entry><entry><author><name>/u/Eden1506</name><uri>https://www.reddit.com/user/Eden1506</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;It doesn&amp;#39;t matter how high those scores are as long as memory (amount&amp;amp;bandwidth) stays the main bottleneck for most AI applications.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n01tl1n</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llnwy5/ai_performance_of_smartphone_socs/n01tl1n/"/><updated>2025-06-27T11:59:29+00:00</updated><title>/u/Eden1506 on AI performance of smartphone SoCs</title></entry><entry><author><name>/u/AyraWinla</name><uri>https://www.reddit.com/user/AyraWinla</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have a Pixel 8a phone (Google Tensor 3; why is it 10% worse than Tensor 2) which I thought was fast compared to other stuff I have. For example, my Samsung S9 FE tablet, with an Exynos 1380.&lt;/p&gt; &lt;p&gt;This benchmark does match that my Pixel runs LLM so much better (829 vs 232 AI score), but I hadn&amp;#39;t realized that my Pixel was actually pretty mediocre in the grand scheme of things!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n021irf</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llnwy5/ai_performance_of_smartphone_socs/n021irf/"/><updated>2025-06-27T12:49:28+00:00</updated><title>/u/AyraWinla on AI performance of smartphone SoCs</title></entry><entry><author><name>/u/VegaKH</name><uri>https://www.reddit.com/user/VegaKH</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;In real-world performance running small local LLM models on the phone, does the Snapdragon 8 Elite actually beat everything else this handily? Are there any benchmarks or just theoretical numbers?&lt;/p&gt; &lt;p&gt;Edit: Looking at the website, this seems to be a compilation of benchmarks. I am just surprised that the Snapdragon 8 Elite it is kicking so much ass, since the Snapdragon X in the AI laptops kicks no ass.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n02ecc6</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llnwy5/ai_performance_of_smartphone_socs/n02ecc6/"/><updated>2025-06-27T13:59:45+00:00</updated><title>/u/VegaKH on AI performance of smartphone SoCs</title></entry><entry><author><name>/u/PhlarnogularMaqulezi</name><uri>https://www.reddit.com/user/PhlarnogularMaqulezi</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Holy Crap, I actually have the top thing of something. Though it&amp;#39;s allegedly modified in some capacity by Samsung. &lt;/p&gt; &lt;p&gt;Sadly the 16GB RAM version of my S25 Ultra wasn&amp;#39;t available through my carrier, that would have been sweet. &lt;/p&gt; &lt;p&gt;Though the phone seems to infer quite fast with the 8B~ models I&amp;#39;ve tried so far&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n02hksg</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llnwy5/ai_performance_of_smartphone_socs/n02hksg/"/><updated>2025-06-27T14:16:02+00:00</updated><title>/u/PhlarnogularMaqulezi on AI performance of smartphone SoCs</title></entry><entry><author><name>/u/Vaddieg</name><uri>https://www.reddit.com/user/Vaddieg</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Irrelevant benchmark. Why not running something more practical like llama-cpp tp/tg bench?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n02n2g3</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llnwy5/ai_performance_of_smartphone_socs/n02n2g3/"/><updated>2025-06-27T14:42:50+00:00</updated><title>/u/Vaddieg on AI performance of smartphone SoCs</title></entry><entry><author><name>/u/Terminator857</name><uri>https://www.reddit.com/user/Terminator857</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Misleading because GPU or tpu does most of the work, not the CPU. the CPUs listed can be paired with different GPU / tpu. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n0509b0</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llnwy5/ai_performance_of_smartphone_socs/n0509b0/"/><updated>2025-06-27T21:35:11+00:00</updated><title>/u/Terminator857 on AI performance of smartphone SoCs</title></entry><entry><author><name>/u/Agreeable_Cat602</name><uri>https://www.reddit.com/user/Agreeable_Cat602</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Apple should be in the top, it&amp;#39;s the superior brand and deserves to be praised. I own an iPhone Pro Max where the max means maximum superiority, this also reflect it&amp;#39;s buyers.&lt;/p&gt; &lt;p&gt;I expect lots of upvotes.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n01on0y</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1llnwy5/ai_performance_of_smartphone_socs/n01on0y/"/><updated>2025-06-27T11:24:49+00:00</updated><title>/u/Agreeable_Cat602 on AI performance of smartphone SoCs</title></entry></feed>