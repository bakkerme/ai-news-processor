<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LocalLLaMA" label="r/LocalLLaMA"/><updated>2025-06-28T00:31:02+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LocalLLaMA/comments/1lm0m6i/copilot_chat_for_vs_code_is_now_open_source/.rss?depth=1</id><link rel="self" href="https://www.reddit.com/r/LocalLLaMA/comments/1lm0m6i/copilot_chat_for_vs_code_is_now_open_source/.rss?depth=1" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LocalLLaMA/comments/1lm0m6i/copilot_chat_for_vs_code_is_now_open_source/?depth=1" type="text/html" /><subtitle>Subreddit to discuss Llama, the large language model created by Meta AI.</subtitle><title>Copilot Chat for VS Code is now Open Source : LocalLLaMA</title><entry><author><name>/u/corysama</name><uri>https://www.reddit.com/user/corysama</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LocalLLaMA/comments/1lm0m6i/copilot_chat_for_vs_code_is_now_open_source/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/tyJeCqipzT78spT8qdYr9nFThGnon2rt0efU2xelzLQ.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=1c7ae49e1d763b069953250103aad9e1f240a4f3&quot; alt=&quot;Copilot Chat for VS Code is now Open Source&quot; title=&quot;Copilot Chat for VS Code is now Open Source&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/corysama&quot;&gt; /u/corysama &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://github.com/microsoft/vscode-copilot-chat&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LocalLLaMA/comments/1lm0m6i/copilot_chat_for_vs_code_is_now_open_source/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1lm0m6i</id><media:thumbnail url="https://external-preview.redd.it/tyJeCqipzT78spT8qdYr9nFThGnon2rt0efU2xelzLQ.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1c7ae49e1d763b069953250103aad9e1f240a4f3" /><link href="https://www.reddit.com/r/LocalLLaMA/comments/1lm0m6i/copilot_chat_for_vs_code_is_now_open_source/" /><updated>2025-06-27T18:00:56+00:00</updated><published>2025-06-27T18:00:56+00:00</published><title>Copilot Chat for VS Code is now Open Source</title></entry><entry><author><name>/u/ArtisticHamster</name><uri>https://www.reddit.com/user/ArtisticHamster</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is it possible to connect it to a local chat provider?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n03v411</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1lm0m6i/copilot_chat_for_vs_code_is_now_open_source/n03v411/"/><updated>2025-06-27T18:09:24+00:00</updated><title>/u/ArtisticHamster on Copilot Chat for VS Code is now Open Source</title></entry><entry><author><name>/u/Threatening-Silence-</name><uri>https://www.reddit.com/user/Threatening-Silence-</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Should be fairly simple to rename the local LLM option away from &amp;quot;Ollama&amp;quot; to something more sensible (&amp;quot;Local OpenAI-compatible LLM&amp;quot; maybe?) and enable it always, even if you have an enterprise/business subscription.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n046x9p</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1lm0m6i/copilot_chat_for_vs_code_is_now_open_source/n046x9p/"/><updated>2025-06-27T19:06:18+00:00</updated><title>/u/Threatening-Silence- on Copilot Chat for VS Code is now Open Source</title></entry><entry><author><name>/u/909876b4-cf8c</name><uri>https://www.reddit.com/user/909876b4-cf8c</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;It still requires having the (closed source) copilot extension and signing in with a github account, even for local-only use? Thanks, but no thanks, Microsoft.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n052wkq</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1lm0m6i/copilot_chat_for_vs_code_is_now_open_source/n052wkq/"/><updated>2025-06-27T21:49:34+00:00</updated><title>/u/909876b4-cf8c on Copilot Chat for VS Code is now Open Source</title></entry><entry><author><name>/u/jakegh</name><uri>https://www.reddit.com/user/jakegh</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Cline/Roo/Kilo are already open-source and much, much better than Copilot. Hopefully they pull the VS Code UI integration stuff out and use it themselves, as that&amp;#39;s the only spot where Copilot is even remotely superior.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_n055nel</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1lm0m6i/copilot_chat_for_vs_code_is_now_open_source/n055nel/"/><updated>2025-06-27T22:04:38+00:00</updated><title>/u/jakegh on Copilot Chat for VS Code is now Open Source</title></entry></feed>