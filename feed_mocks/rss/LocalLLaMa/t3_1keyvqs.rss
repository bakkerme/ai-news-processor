<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LocalLLaMA" label="r/LocalLLaMA"/><updated>2025-05-05T05:32:11+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LocalLLaMA/comments/1keyvqs/is_it_possible_to_system_prompt_qwen_3_models_to/.rss?depth=1</id><link rel="self" href="https://www.reddit.com/r/LocalLLaMA/comments/1keyvqs/is_it_possible_to_system_prompt_qwen_3_models_to/.rss?depth=1" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LocalLLaMA/comments/1keyvqs/is_it_possible_to_system_prompt_qwen_3_models_to/?depth=1" type="text/html" /><subtitle>Subreddit to discuss about Llama, the large language model created by Meta AI.</subtitle><title>Is it possible to system prompt Qwen 3 models to have &quot;reasoning effort&quot;? : LocalLLaMA</title><entry><author><name>/u/wunnsen</name><uri>https://www.reddit.com/user/wunnsen</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m wondering if I can prompt Qwen 3 models to output shorter / longer / more concise think tags.&lt;br/&gt; Has anyone attempted this yet for Qwen or a similar model?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/wunnsen&quot;&gt; /u/wunnsen &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LocalLLaMA/comments/1keyvqs/is_it_possible_to_system_prompt_qwen_3_models_to/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LocalLLaMA/comments/1keyvqs/is_it_possible_to_system_prompt_qwen_3_models_to/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1keyvqs</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1keyvqs/is_it_possible_to_system_prompt_qwen_3_models_to/" /><updated>2025-05-05T00:36:01+00:00</updated><published>2025-05-05T00:36:01+00:00</published><title>Is it possible to system prompt Qwen 3 models to have &quot;reasoning effort&quot;?</title></entry><entry><author><name>/u/Googulator</name><uri>https://www.reddit.com/user/Googulator</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hosted versions of Qwen 3 have a &amp;quot;reasoning budget&amp;quot; feature, not sure how that&amp;#39;s implemented&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mqmx52l</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1keyvqs/is_it_possible_to_system_prompt_qwen_3_models_to/mqmx52l/"/><updated>2025-05-05T01:36:08+00:00</updated><title>/u/Googulator on Is it possible to system prompt Qwen 3 models to have &quot;reasoning effort&quot;?</title></entry><entry><author><name>/u/Turkino</name><uri>https://www.reddit.com/user/Turkino</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Yeah mine is quite happy to burn between 600 and 900 tokens just on the think portion alone.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mqnooku</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1keyvqs/is_it_possible_to_system_prompt_qwen_3_models_to/mqnooku/"/><updated>2025-05-05T04:44:20+00:00</updated><title>/u/Turkino on Is it possible to system prompt Qwen 3 models to have &quot;reasoning effort&quot;?</title></entry><entry><author><name>/u/ForsookComparison</name><uri>https://www.reddit.com/user/ForsookComparison</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;You can try.&lt;/p&gt; &lt;p&gt;People claimed success with QwQ, but I could never recreate it reliably - so I&amp;#39;ve come to the conclusion that it&amp;#39;s impossible. Right now models trained to think will think as long or as short as they please. Deepseek thinks for a bit, Qwen3 thinks for a longer while, and QwQ will think until it finds a perfect answer or you run out of system memory.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mqmud7v</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1keyvqs/is_it_possible_to_system_prompt_qwen_3_models_to/mqmud7v/"/><updated>2025-05-05T01:19:21+00:00</updated><title>/u/ForsookComparison on Is it possible to system prompt Qwen 3 models to have &quot;reasoning effort&quot;?</title></entry><entry><author><name>/u/suprjami</name><uri>https://www.reddit.com/user/suprjami</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;No.&lt;/p&gt; &lt;p&gt;Qwen3 only provides two modes:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;reasoning on (default, and with &lt;code&gt;/think&lt;/code&gt; token)&lt;/li&gt; &lt;li&gt;reasoning off (with &lt;code&gt;/no_think&lt;/code&gt; token)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Qwen3 does not implement a reasoning effort API like OpenAI o1 and o3.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mqmqd6l</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1keyvqs/is_it_possible_to_system_prompt_qwen_3_models_to/mqmqd6l/"/><updated>2025-05-05T00:54:59+00:00</updated><title>/u/suprjami on Is it possible to system prompt Qwen 3 models to have &quot;reasoning effort&quot;?</title></entry></feed>