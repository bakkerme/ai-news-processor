<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LocalLLaMA" label="r/LocalLLaMA"/><updated>2025-05-05T05:32:12+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LocalLLaMA/comments/1keh382/local_deep_research_v031_we_need_your_help_for/.rss?depth=1</id><link rel="self" href="https://www.reddit.com/r/LocalLLaMA/comments/1keh382/local_deep_research_v031_we_need_your_help_for/.rss?depth=1" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LocalLLaMA/comments/1keh382/local_deep_research_v031_we_need_your_help_for/?depth=1" type="text/html" /><subtitle>Subreddit to discuss about Llama, the large language model created by Meta AI.</subtitle><title>Local Deep Research v0.3.1: We need your help for improving the tool : LocalLLaMA</title><entry><author><name>/u/ComplexIt</name><uri>https://www.reddit.com/user/ComplexIt</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey guys, we are trying to improve LDR. &lt;/p&gt; &lt;p&gt;What areas do need attention in your opinion? - What features do you need? - What types of research you need? - How to improve the UI?&lt;/p&gt; &lt;p&gt;Repo: &lt;a href=&quot;https://github.com/LearningCircuit/local-deep-research&quot;&gt;https://github.com/LearningCircuit/local-deep-research&lt;/a&gt;&lt;/p&gt; &lt;h3&gt;Quick install:&lt;/h3&gt; &lt;p&gt;```bash pip install local-deep-research python -m local_deep_research.web.app&lt;/p&gt; &lt;h1&gt;For SearXNG (highly recommended):&lt;/h1&gt; &lt;p&gt;docker pull searxng/searxng docker run -d -p 8080:8080 --name searxng searxng/searxng&lt;/p&gt; &lt;h1&gt;Start SearXNG (Required after system restart)&lt;/h1&gt; &lt;p&gt;docker start searxng ```&lt;/p&gt; &lt;p&gt;(Use Direct SearXNG for maximum speed instead of &amp;quot;auto&amp;quot; - this bypasses the LLM calls needed for engine selection in auto mode)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/ComplexIt&quot;&gt; /u/ComplexIt &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LocalLLaMA/comments/1keh382/local_deep_research_v031_we_need_your_help_for/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LocalLLaMA/comments/1keh382/local_deep_research_v031_we_need_your_help_for/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_1keh382</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1keh382/local_deep_research_v031_we_need_your_help_for/" /><updated>2025-05-04T10:53:51+00:00</updated><published>2025-05-04T10:53:51+00:00</published><title>Local Deep Research v0.3.1: We need your help for improving the tool</title></entry><entry><author><name>/u/Felladrin</name><uri>https://www.reddit.com/user/Felladrin</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Great to see more open-source research tools coming up!&lt;br/&gt; I&amp;#39;ve added it to the &lt;a href=&quot;https://huggingface.co/spaces/Felladrin/awesome-ai-web-search&quot;&gt;awesome-ai-web-search&lt;/a&gt; list.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mqirpl5</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1keh382/local_deep_research_v031_we_need_your_help_for/mqirpl5/"/><updated>2025-05-04T11:41:00+00:00</updated><title>/u/Felladrin on Local Deep Research v0.3.1: We need your help for improving the tool</title></entry><entry><author><name>/u/YearnMar10</name><uri>https://www.reddit.com/user/YearnMar10</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have a jetson Orin nano super with limited ram. I am already hosting a llama.cpp server and canâ€™t afford to host another LLM instance. Is it possible to use my own llama.cpp server instead of something thatâ€™s hosted by LDR?&lt;/p&gt; &lt;p&gt;Edited read through the readme - itâ€™s possible. Nice!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mqj4ku9</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1keh382/local_deep_research_v031_we_need_your_help_for/mqj4ku9/"/><updated>2025-05-04T13:13:26+00:00</updated><title>/u/YearnMar10 on Local Deep Research v0.3.1: We need your help for improving the tool</title></entry><entry><author><name>/u/deejeycris</name><uri>https://www.reddit.com/user/deejeycris</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;This looks amazing, will try it out right away&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mqitzas</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1keh382/local_deep_research_v031_we_need_your_help_for/mqitzas/"/><updated>2025-05-04T11:59:07+00:00</updated><title>/u/deejeycris on Local Deep Research v0.3.1: We need your help for improving the tool</title></entry><entry><author><name>/u/Tracing1701</name><uri>https://www.reddit.com/user/Tracing1701</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Better documentation and bugfixing, I spent 2 days getting this to work only to find out that python 3.11 (I think) instead of 3.13 or 3.10 or anything else was the problem.&lt;/p&gt; &lt;p&gt;Additionally, can we have duckduckgo as a search engine. I know of another researcher that uses it.&lt;/p&gt; &lt;p&gt;Some more way to control the output beyond summary or detailed report may also be good.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mqk1asu</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1keh382/local_deep_research_v031_we_need_your_help_for/mqk1asu/"/><updated>2025-05-04T16:11:51+00:00</updated><title>/u/Tracing1701 on Local Deep Research v0.3.1: We need your help for improving the tool</title></entry><entry><author><name>/u/Zestyclose-Ad-6147</name><uri>https://www.reddit.com/user/Zestyclose-Ad-6147</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;It would be amazing if it was available in the Unraid community app store. I tried installing it this morning, but I didnâ€™t got it to work ðŸ˜…. Really interesting project btw!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mqj8g7h</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1keh382/local_deep_research_v031_we_need_your_help_for/mqj8g7h/"/><updated>2025-05-04T13:37:12+00:00</updated><title>/u/Zestyclose-Ad-6147 on Local Deep Research v0.3.1: We need your help for improving the tool</title></entry><entry><author><name>/u/Initial-Swan6385</name><uri>https://www.reddit.com/user/Initial-Swan6385</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;What about include some benchmarks?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mqk0hey</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1keh382/local_deep_research_v031_we_need_your_help_for/mqk0hey/"/><updated>2025-05-04T16:07:36+00:00</updated><title>/u/Initial-Swan6385 on Local Deep Research v0.3.1: We need your help for improving the tool</title></entry><entry><author><name>/u/TemperatureOk3561</name><uri>https://www.reddit.com/user/TemperatureOk3561</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;DuckDuckGo as a search engine with no api&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mqm9z72</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1keh382/local_deep_research_v031_we_need_your_help_for/mqm9z72/"/><updated>2025-05-04T23:17:45+00:00</updated><title>/u/TemperatureOk3561 on Local Deep Research v0.3.1: We need your help for improving the tool</title></entry></feed>