<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="LocalLLaMA" label="r/LocalLLaMA"/><updated>2025-04-21T06:26:20+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/.rss?depth=1</id><link rel="self" href="https://www.reddit.com/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/.rss?depth=1" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/?depth=1" type="text/html" /><subtitle>Subreddit to discuss about Llama, the large language model created by Meta AI.</subtitle><title>We GRPO-ed a Model to Keep Retrying 'Search' Until It Found What It Needed : LocalLLaMA</title><entry><author><name>/u/Kooky-Somewhere-2883</name><uri>https://www.reddit.com/user/Kooky-Somewhere-2883</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/OTVoem9nbmRsNHZlMRZyoyYKNpzPJZZUnGrUtyeCYi3ToyFLi7JPjGL-ftCw.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=1b12cd479c2024bd0aed4acb204f01a7a4780624&quot; alt=&quot;We GRPO-ed a Model to Keep Retrying 'Search' Until It Found What It Needed&quot; title=&quot;We GRPO-ed a Model to Keep Retrying 'Search' Until It Found What It Needed&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey everyone, it&amp;#39;s Menlo Research again, and today we‚Äôd like to introduce a new paper from our team related to search.&lt;/p&gt; &lt;p&gt;Have you ever felt that when searching on Google, &lt;strong&gt;you know for sure there‚Äôs no way you‚Äôll get the result you want on the first try&lt;/strong&gt; (you‚Äôre already mentally prepared for 3-4 attempts)? ReZero, which we just trained, is based on this very idea.&lt;/p&gt; &lt;p&gt;We used GRPO and tool-calling to train a model with a retry_reward and tested whether, if we made the model &amp;quot;work harder&amp;quot; and be more diligent, it could actually perform better.&lt;/p&gt; &lt;p&gt;Normally when training LLMs, repetitive actions are something people want to avoid, because they‚Äôre thought to cause hallucinations - maybe. But the results from ReZero are pretty interesting. We got a performance score of &lt;strong&gt;46%&lt;/strong&gt;, compared to just &lt;strong&gt;20%&lt;/strong&gt; from a baseline model trained the same way. So that gives us some evidence that &lt;strong&gt;Repetition is not hallucination.&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;There are a few ideas for application. The model could act as an abstraction layer over the main LLM loop, so that the main LLM can search better. Or simply an abstraction layer on top of current search engines to help you generate more relevant queries - a query generator - perfect for research use cases.&lt;/p&gt; &lt;p&gt;Attached a demo in the clip.&lt;/p&gt; &lt;p&gt;(The beginning has a little meme to bring you some laughs üòÑ - Trust me ReZero is Retry and Zero from Deepseek-zero)&lt;/p&gt; &lt;p&gt;Links to the paper/data below:&lt;/p&gt; &lt;p&gt;paper: &lt;a href=&quot;https://arxiv.org/abs/2504.11001&quot;&gt;https://arxiv.org/abs/2504.11001&lt;/a&gt;&lt;br/&gt; huggingface: &lt;a href=&quot;https://huggingface.co/Menlo/ReZero-v0.1-llama-3.2-3b-it-grpo-250404&quot;&gt;https://huggingface.co/Menlo/ReZero-v0.1-llama-3.2-3b-it-grpo-250404&lt;/a&gt;&lt;br/&gt; github: &lt;a href=&quot;https://github.com/menloresearch/ReZero&quot;&gt;https://github.com/menloresearch/ReZero&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; As much as we want to make this model perfect, we are well aware of its limitations, specifically about training set and a bit poor design choice of reward functions. However we decided to release the model anyway, because it&amp;#39;s better for the community to have access and play with it (also our time budget for this research is already up).&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Kooky-Somewhere-2883&quot;&gt; /u/Kooky-Somewhere-2883 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://v.redd.it/x9c46kt8l4ve1&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_1k0c40c</id><media:thumbnail url="https://external-preview.redd.it/OTVoem9nbmRsNHZlMRZyoyYKNpzPJZZUnGrUtyeCYi3ToyFLi7JPjGL-ftCw.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1b12cd479c2024bd0aed4acb204f01a7a4780624" /><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/" /><updated>2025-04-16T04:38:13+00:00</updated><published>2025-04-16T04:38:13+00:00</published><title>We GRPO-ed a Model to Keep Retrying 'Search' Until It Found What It Needed</title></entry><entry><author><name>/u/MoffKalast</name><uri>https://www.reddit.com/user/MoffKalast</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Ah finally, the &amp;quot;work harder, not smarter&amp;quot; approach.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mneizvd</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/mneizvd/"/><updated>2025-04-16T13:08:54+00:00</updated><title>/u/MoffKalast on We GRPO-ed a Model to Keep Retrying 'Search' Until It Found What It Needed</title></entry><entry><author><name>/u/Kooky-Somewhere-2883</name><uri>https://www.reddit.com/user/Kooky-Somewhere-2883</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://preview.redd.it/9gddv47fz4ve1.png?width=1522&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=67ac258882a6a75ca4b1be80969d6a350bc2c589&quot;&gt;https://preview.redd.it/9gddv47fz4ve1.png?width=1522&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=67ac258882a6a75ca4b1be80969d6a350bc2c589&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnd5t4r</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/mnd5t4r/"/><updated>2025-04-16T05:55:24+00:00</updated><title>/u/Kooky-Somewhere-2883 on We GRPO-ed a Model to Keep Retrying 'Search' Until It Found What It Needed</title></entry><entry><author><name>/u/LightMaleficent5844</name><uri>https://www.reddit.com/user/LightMaleficent5844</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Didn&amp;#39;t expect F1 race spoilers here. I&amp;#39;ll pretend it&amp;#39;s wrong because it&amp;#39;s an LLM after all, hahah..&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mndlgqr</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/mndlgqr/"/><updated>2025-04-16T08:38:16+00:00</updated><title>/u/LightMaleficent5844 on We GRPO-ed a Model to Keep Retrying 'Search' Until It Found What It Needed</title></entry><entry><author><name>/u/hiepxanh</name><uri>https://www.reddit.com/user/hiepxanh</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I love rezero ‚ù§&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnehg85</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/mnehg85/"/><updated>2025-04-16T13:00:24+00:00</updated><title>/u/hiepxanh on We GRPO-ed a Model to Keep Retrying 'Search' Until It Found What It Needed</title></entry><entry><author><name>/u/qnixsynapse</name><uri>https://www.reddit.com/user/qnixsynapse</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Nice!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mncxh0y</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/mncxh0y/"/><updated>2025-04-16T04:43:37+00:00</updated><title>/u/qnixsynapse on We GRPO-ed a Model to Keep Retrying 'Search' Until It Found What It Needed</title></entry><entry><author><name>/u/martinerous</name><uri>https://www.reddit.com/user/martinerous</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Interesting.&lt;/p&gt; &lt;p&gt;Still, it makes me wonder, how often does it &amp;quot;over-try&amp;quot; and choose a worse result from the second try instead of a better one it happened to find on the first try?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mndhrhb</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/mndhrhb/"/><updated>2025-04-16T07:57:44+00:00</updated><title>/u/martinerous on We GRPO-ed a Model to Keep Retrying 'Search' Until It Found What It Needed</title></entry><entry><author><name>/u/digitalthiccness</name><uri>https://www.reddit.com/user/digitalthiccness</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I just have to point out how perilously close the title is to &amp;quot;We groped a model.&amp;quot; Do with this what you will.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mne6b7h</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/mne6b7h/"/><updated>2025-04-16T11:49:55+00:00</updated><title>/u/digitalthiccness on We GRPO-ed a Model to Keep Retrying 'Search' Until It Found What It Needed</title></entry><entry><author><name>/u/JuliosJourney_</name><uri>https://www.reddit.com/user/JuliosJourney_</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Interesting results! Putting it out there for those interested in Multi-Hop retrieval: There are already LLM based embedding models (essentially using the last time state of a decoder as the embedding) that are trained for automated efficient multi-hop retrieval. The model only does forward passes and decides when to stop retrieving new information for the user query without query decomposition or rewriting. This saves all of the generation and tool calling. GritHopper or GritLM on Hugging face are an example for that. ‚úåüèª&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnjtf5m</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/mnjtf5m/"/><updated>2025-04-17T08:02:02+00:00</updated><title>/u/JuliosJourney_ on We GRPO-ed a Model to Keep Retrying 'Search' Until It Found What It Needed</title></entry><entry><author><name>/u/Kooky-Somewhere-2883</name><uri>https://www.reddit.com/user/Kooky-Somewhere-2883</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Big thanks to dCaples on &lt;a href=&quot;https://github.com/dCaples/AutoDidact&quot;&gt;https://github.com/dCaples/AutoDidact&lt;/a&gt; and Unsloth &lt;a href=&quot;https://github.com/unslothai/unsloth&quot;&gt;https://github.com/unslothai/unsloth&lt;/a&gt; for the toolset we used to train the model.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mncxb4h</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/mncxb4h/"/><updated>2025-04-16T04:42:21+00:00</updated><title>/u/Kooky-Somewhere-2883 on We GRPO-ed a Model to Keep Retrying 'Search' Until It Found What It Needed</title></entry><entry><author><name>/u/yoracale</name><uri>https://www.reddit.com/user/yoracale</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Super cool guys!! Is the reward function/verifier in the repo?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnczauq</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/mnczauq/"/><updated>2025-04-16T04:57:52+00:00</updated><title>/u/yoracale on We GRPO-ed a Model to Keep Retrying 'Search' Until It Found What It Needed</title></entry><entry><author><name>/u/Kooky-Somewhere-2883</name><uri>https://www.reddit.com/user/Kooky-Somewhere-2883</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Thank you for drinking the tea üôá!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mndk5ye</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/mndk5ye/"/><updated>2025-04-16T08:23:53+00:00</updated><title>/u/Kooky-Somewhere-2883 on We GRPO-ed a Model to Keep Retrying 'Search' Until It Found What It Needed</title></entry><entry><author><name>/u/SnooSprouts1512</name><uri>https://www.reddit.com/user/SnooSprouts1512</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Funny how ideas often pop up at the same time. Independently from you guys I&amp;#39;ve build a commercial product around this that is ready for production deployments. quick question though, why don&amp;#39;t you do parallel search? meaning you chunk up your dataset in X chunks and you run your ReZEro query on each chunk of your dataset so that you can combine it all at the end this is how we reduced our query speed at &lt;a href=&quot;http://Spyk.io&quot;&gt;Spyk.io&lt;/a&gt; We get the results you need in about 2-8 seconds with this strategy&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mndpak5</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/mndpak5/"/><updated>2025-04-16T09:19:46+00:00</updated><title>/u/SnooSprouts1512 on We GRPO-ed a Model to Keep Retrying 'Search' Until It Found What It Needed</title></entry><entry><author><name>/u/nbeydoon</name><uri>https://www.reddit.com/user/nbeydoon</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;That&amp;#39;a really cool idea!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mndrijd</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/mndrijd/"/><updated>2025-04-16T09:43:15+00:00</updated><title>/u/nbeydoon on We GRPO-ed a Model to Keep Retrying 'Search' Until It Found What It Needed</title></entry><entry><author><name>/u/qnixsynapse</name><uri>https://www.reddit.com/user/qnixsynapse</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://preview.redd.it/oi1y79g2j6ve1.png?width=531&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3c7d8d8b573692b0ae5b3133fb1a7af506676d51&quot;&gt;https://preview.redd.it/oi1y79g2j6ve1.png?width=531&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3c7d8d8b573692b0ae5b3133fb1a7af506676d51&lt;/a&gt;&lt;/p&gt; &lt;p&gt;This is an awesome idea! üëè&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mne0qje</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/mne0qje/"/><updated>2025-04-16T11:07:33+00:00</updated><title>/u/qnixsynapse on We GRPO-ed a Model to Keep Retrying 'Search' Until It Found What It Needed</title></entry><entry><author><name>/u/AdventurousFly4909</name><uri>https://www.reddit.com/user/AdventurousFly4909</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;How do you know if it has the right answer?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnemh41</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/mnemh41/"/><updated>2025-04-16T13:29:15+00:00</updated><title>/u/AdventurousFly4909 on We GRPO-ed a Model to Keep Retrying 'Search' Until It Found What It Needed</title></entry><entry><author><name>/u/shing3232</name><uri>https://www.reddit.com/user/shing3232</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;this could build based on deepscaler to keep improve 1.5B level model performance&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnexlod</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/mnexlod/"/><updated>2025-04-16T14:28:56+00:00</updated><title>/u/shing3232 on We GRPO-ed a Model to Keep Retrying 'Search' Until It Found What It Needed</title></entry><entry><author><name>/u/Rectangularbox23</name><uri>https://www.reddit.com/user/Rectangularbox23</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Mad funny model name&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnix87n</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/mnix87n/"/><updated>2025-04-17T03:17:50+00:00</updated><title>/u/Rectangularbox23 on We GRPO-ed a Model to Keep Retrying 'Search' Until It Found What It Needed</title></entry><entry><author><name>/u/TechnicallySerizon</name><uri>https://www.reddit.com/user/TechnicallySerizon</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Can you guys provide me a hugging face space for this please?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mnjxts9</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/mnjxts9/"/><updated>2025-04-17T08:49:01+00:00</updated><title>/u/TechnicallySerizon on We GRPO-ed a Model to Keep Retrying 'Search' Until It Found What It Needed</title></entry><entry><author><name>/u/ThaisaGuilford</name><uri>https://www.reddit.com/user/ThaisaGuilford</uri></author><category term="LocalLLaMA" label="r/LocalLLaMA" /><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Why is it anime&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt;</content><id>t1_mndf110</id><link href="https://www.reddit.com/r/LocalLLaMA/comments/1k0c40c/we_grpoed_a_model_to_keep_retrying_search_until/mndf110/"/><updated>2025-04-16T07:28:29+00:00</updated><title>/u/ThaisaGuilford on We GRPO-ed a Model to Keep Retrying 'Search' Until It Found What It Needed</title></entry></feed>